import joblib
import os
import torch
import time
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding
from transformers import TextClassificationPipeline
from datasets import Dataset
from utils import free_gpu, diagnostic_report

torch.cuda.empty_cache()

class Detector:
    def __init__(self, model="tfidf", model_dir=None, load_if_exists=True):
        self.model_name = model.lower()
        self.model_dir = model_dir or os.path.join("models", self.model_name)

        model_exists = os.path.isdir(self.model_dir)

        if self.model_name == "tfidf":
            self.detector = TFIDFDetector()
            if model_exists and load_if_exists:
                self.detector.load(self.model_dir)

        elif model_exists and Detector.is_valid_hf_model(self.model_dir) and load_if_exists:
            self.detector = BertLikeDetector(model_name=model_dir)
            self.detector.load(self.model_dir)
        
        elif not load_if_exists:
            self.detector = BertLikeDetector(model_name=self.model_name)

        else:
            raise FileNotFoundError(f"Model directory '{self.model_dir}' not found or is invalid")
    
    @staticmethod
    def is_valid_hf_model(path: str) -> bool:
        required_files = ["config.json", "pytorch_model.bin"]
        return all(os.path.isfile(os.path.join(path, f)) for f in required_files)
    
    @classmethod
    def custom(cls, model_name, save_as=None):
        """
        Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ñ‚ BertLikeDetector Ñ ÐºÐ°ÑÑ‚Ð¾Ð¼Ð½Ñ‹Ð¼ Hugging Face Ð¼Ð¾Ð´ÐµÐ»ÑŒÑŽ.
        save_as â€” Ð¸Ð¼Ñ Ð¿Ð°Ð¿ÐºÐ¸ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'my_rubert')
        """
        path = os.path.join("models", save_as or model_name.replace("/", "_"))
        return cls(model=model_name, model_dir=path, load_if_exists=False)
    
    @staticmethod
    def list_models():
        base_dir = "models"
        if not os.path.isdir(base_dir):
            return []
        return [
            name for name in os.listdir(base_dir)
            if os.path.isdir(os.path.join(base_dir, name)) and
            Detector.is_valid_hf_model(os.path.join(base_dir, name)) or name == "tfidf"
        ]
    
    @staticmethod
    def is_model_available(name):
        return name == "tfidf" or Detector.is_valid_hf_model(os.path.join("models", name))

    def train(self, texts, labels, output_dir="model_output", **kwargs):
        free_gpu()
        diagnostic_report(texts, labels)
        self.detector.train(texts, labels, output_dir=output_dir, **kwargs)

    def evaluate(self, texts, labels):
        return self.detector.evaluate(texts, labels)

    def predict(self, text_or_texts):
        if isinstance(text_or_texts, list):
            return self.detector.predict(text_or_texts)
        return self.detector.predict([text_or_texts])[0]

    def predict_batch(self, texts):
        return [self.predict(t) for t in texts]

    def save(self, path="models/"):
        model_path = os.path.join(path, self.model_name)
        self.detector.save(model_path)

    def load(self, path="models/"):
        model_path = os.path.join(path, self.model_name)
        self.detector.load(model_path)

    def get_name(self):
        return self.model_name
    
    def benchmark(self, texts):
        import time
        start = time.time()
        self.predict(texts)
        print(f"Time for {len(texts)} predictions: {time.time() - start:.2f} sec")

class TFIDFDetector:
    def __init__(self, max_features=5000, ngram_range=(1, 2)):
        self.vectorizer = TfidfVectorizer(max_features=max_features, ngram_range=ngram_range)
        self.model = LogisticRegression(class_weight='balanced', max_iter=1000)
        self.is_fitted = False

    def train(self, texts: list, labels: list, **kwargs) -> None:
        """
        ÐžÐ±ÑƒÑ‡Ð°ÐµÑ‚ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ð° Ð½Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ….
        """
        X = self.vectorizer.fit_transform(texts)
        self.model.fit(X, labels)
        self.is_fitted = True

    def predict(self, texts: list):
        """
        ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð¼ÐµÑ‚ÐºÐ¸ Ð´Ð»Ñ Ð½Ð¾Ð²Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹.
        """
        if not self.is_fitted:
            raise ValueError("Model is not trained or loaded.")
        
        X = self.vectorizer.transform(texts)
        return self.model.predict(X)

    def predict_proba(self, texts: list):
        """
        Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ ÐºÐ»Ð°ÑÑÐ¾Ð².
        """
        if not self.is_fitted:
            raise ValueError("Model is not trained or loaded.")
        
        X = self.vectorizer.transform(texts)
        return self.model.predict_proba(X)

    def evaluate(self, texts: list, labels: list) -> None:
        """
        ÐžÑ†ÐµÐ½Ð¸Ð²Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: accuracy, precision, recall, f1, confusion matrix.
        """
        y_pred = self.predict(texts)
        print("Confusion matrix:\n", confusion_matrix(labels, y_pred))
        print("\nClassification report:\n", classification_report(labels, y_pred))

    def save(self, path="models/") -> None:
        """
        Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð² Ð¿Ð°Ð¿ÐºÑƒ.
        """
        os.makedirs(path, exist_ok=True)

        joblib.dump(self.vectorizer, os.path.join(path, "vectorizer.pkl"))
        joblib.dump(self.model, os.path.join(path, "model.pkl"))

    def load(self, path="models/") -> None:
        """
        Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸.
        """
        self.vectorizer = joblib.load(os.path.join(path, "vectorizer.pkl"))
        self.model = joblib.load(os.path.join(path, "model.pkl"))
        self.is_fitted = True

class BertLikeDetector:
    def __init__(self, model_name="distilbert-base-uncased"):
        self.model_name = model_name
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)
        self.pipeline = None
        self.is_trained = False
        self.batch_size = 16 if torch.cuda.is_available() else 4

    def train(self, texts, labels, output_dir="bert_model", epochs=3, batch_size=8):
        dataset = Dataset.from_dict({"text": texts, "label": labels})
        dataset = dataset.train_test_split(test_size=0.2)

        def tokenize(example):
            return self.tokenizer(
                example["text"],
                truncation=True,
                padding="max_length",
                max_length=self.tokenizer.model_max_length)
        
        tokenized = dataset.map(tokenize, batched=True)

        args = TrainingArguments(
            output_dir=output_dir,
            eval_strategy="epoch",
            per_device_train_batch_size=batch_size if batch_size else self.batch_size,
            per_device_eval_batch_size=batch_size if batch_size else self.batch_size,
            num_train_epochs=epochs,
            logging_dir=f"{output_dir}/logs",
            save_strategy="no",
            load_best_model_at_end=False
        )

        trainer = Trainer(
            model=self.model,
            args=args,
            train_dataset=tokenized["train"],
            eval_dataset=tokenized["test"],
            data_collator=DataCollatorWithPadding(tokenizer=self.tokenizer)
        )

        trainer.train()

        if torch.cuda.is_available():
            print(f"ðŸ“ˆ After train start: allocated = {torch.cuda.memory_allocated() / 1024**2:.2f} MB, reserved = {torch.cuda.memory_reserved() / 1024**2:.2f} MB")

        self.is_trained = True

    def predict(self, texts):
        if not self.is_trained:
            raise ValueError("Model is not trained or loaded.")

        if self.pipeline is None:
            self.pipeline = TextClassificationPipeline(
                model=self.model,
                tokenizer=self.tokenizer,
                truncation=True,
                padding=True,
                max_length=self.tokenizer.model_max_length,
                device=0 if torch.cuda.is_available() else -1,
                batch_size=self.batch_size)
        
        outputs = self.pipeline(texts, batch_size=self.batch_size)
        return [int(o["label"].split("_")[-1]) for o in outputs]

    def predict_proba(self, texts):
        if self.pipeline is None:
            self.pipeline = TextClassificationPipeline(
                model=self.model,
                tokenizer=self.tokenizer,
                truncation=True,
                padding=True,
                max_length=self.tokenizer.model_max_length,
                device=0 if torch.cuda.is_available() else -1,
                batch_size=self.batch_size,
                return_all_scores=True)
            
        results = self.pipeline(texts, batch_size=self.batch_size, return_all_scores=True)
        return [[score['score'] for score in output] for output in results]

    def evaluate(self, texts, labels):
        preds = self.predict(texts)
        print("=== Confusion matrix ===")
        print(confusion_matrix(labels, preds))
        print("=== Report ===")
        print(classification_report(labels, preds))
        print("Accuracy:", accuracy_score(labels, preds))
        return preds

    def save(self, path="models/"): 
        if not os.path.exists(path):
            os.makedirs(path)

        full_path = os.path.join(path, self.model_name)
        self.model.save_pretrained(full_path)
        self.tokenizer.save_pretrained(full_path)

    def load(self, path="models/"):
        full_path = os.path.join(path, self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(full_path)
        self.tokenizer = AutoTokenizer.from_pretrained(full_path)
        self.pipeline = TextClassificationPipeline(
            model=self.model,
            tokenizer=self.tokenizer,
            truncation=True,
            padding=True,
            max_length=self.tokenizer.model_max_length,
            device=0 if torch.cuda.is_available() else -1,
            batch_size=self.batch_size)
        
        self.is_trained = True
